{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('../Refined Dataset.csv'))[:, -1]\n",
    "split = int(0.1*data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23821,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:split]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Oh baby, how you doing?\\nYou know I'm gonna cut right to the chase\\nSome women were made but me, myself\\nI like to think that I was created for a special purpose\\nYou know, what's more special than you? You feel me\\nIt's on baby, let's get lost\\nYou don't need to call into work 'cause you're the boss\\nFor real, want you to show me how you feel\\nI consider myself lucky, that's a big deal\\nWhy? Well, you got the key to my heart\\nBut you ain't gonna need it, I'd rather you open up my body\\nAnd show me secrets, you didn't know was inside\\nNo need for me to lie\\nIt's too big, it's too wide\\nIt's too strong, it won't fit\\nIt's too much, it's too tough\\nHe talk like this 'cause he can back it up\\nHe got a big ego, such a huge ego\\nI love his big ego, it's too much\\nHe walk like this 'cause he can back it up\\nUsually I'm humble, right now I don't choose\\nYou can leave with me or you could have the blues\\nSome call it arrogant, I call it confident\\nYou decide when you find on what I'm working with\\nDamn I know I'm killing you with them legs\\nBetter yet them thighs\\nMatter a fact it's my smile or maybe my eyes\\nBoy you a site to see, kind of something like me\\nIt's too big, it's too wide\\nIt's too strong, it won't fit\\nIt's too much, it's too tough\\nI talk like this 'cause I can back it up\\nI got a big ego, such a huge ego\\nBut he love my big ego, it's too much\\nI walk like this 'cause I can back it up\\nI, I walk like this 'cause I can back it up\\nI, I talk like this 'cause I can back it up\\nI, I can back it up, I can back it up\\nI walk like this 'cause I can back it up\\nIt's too big, it's too wide\\nIt's too strong, it won't fit\\nIt's too much, it's too tough\\nHe talk like this 'cause he can back it up\\nHe got a big ego, such a huge ego, such a huge ego\\nI love his big ego, it's too much\\nHe walk like this 'cause he can back it up\\nEgo so big, you must admit\\nI got every reason to feel like I'm that bitch\\nEgo so strong, if you ain't know\\nI don't need no beat, I can sing it with piano\",\n",
       "       \"playin' everything so easy,\\nit's like you seem so sure.\\nstill your ways, you dont see\\ni'm not sure if they're for me.\\nthen things come right along our way, though we didn't truly ask.\\nit seems as if they're gonna linger\\nwith every delight they bring,\\njust like what you have truly seemed.\\ni'm trying to think of what you really want to say,\\neven through my darkest day.\\nyou might want to leave me,\\nfeeling strange about you\\nlike you're gonna let me know,\\nwhen words then slipped out of you.\\nwhen words dont come so easy to say\\nyou just leave me feeling, come what may\\nthough i want things coming from your way.\\ni say to you, you bore me all the time\\nwhen you seem to hold back all in you,\\nall that you want to let me know.\\nwhy dont you have the courage?\\nspeak up and i'll listen,\\nif you truly want me to know, then tell me.\\nis there something wrong with you\\nand you seem fastened there.\\nit sounds as if there'll be a melody\\nif things in you are let out\\nand then i will feel alright.\\nwhen you sleep, do you feel the same,\\nexactly as i do?\\ni really want to hear things from you,\\nthough i've felt something new\\neversince you acted that way.\\nif i go,\\nwould you still mind telling me?\\nif i stay,\\nyou seem to let the days go by.\\nif you truly want to let me know,\\nthen tell me.\",\n",
       "       \"If you search\\nFor tenderness\\nIt isn't hard to find\\nYou can have the love\\nYou need to live\\nBut if you look\\nFor truthfulness\\nYou might just\\nAs well be blind\\nIt always seems to be\\nSo hard to give\\nChorus:\\nHonesty\\nIs such a lonely word\\nEveryone is so untrue\\nHonesty\\nIs hardly ever heard\\nAnd mostly\\nWhat I need from you\\nI can always\\nFind someone\\nTo say\\nThey sympathize\\nIf I wear my heart\\nOut on my sleeve\\nBut I don't want\\nSome pretty face\\nTo tell me\\nPretty lies\\nAll I want\\nIs someone\\nTo believe\\n(Chorus)\\nI can find a lover\\nI can find a friend\\nI can have security\\nUntil the bitter end\\nAnyone can comfort me\\nWith promises again\\nI know, I know\\nWhen I'm deep\\nInside of me\\nDon't be\\nToo concerned\\nI won't ask\\nFor nothin'\\nWhile I'm gone\\nBut when I want\\nSincerity\\nTell me where else\\nCan I turn\\nWhen\\nYou're the one\\nThat I depend upon\\n(Chorus)\",\n",
       "       ...,\n",
       "       \"It's a long, long journey\\n'Til I know where I'm supposed to be\\nIt's a long, long journey\\nAnd I don't know if I can believe\\nWhen shadows fall and block my eyes\\nI am lost and know that I must hide\\nIt's a long, long journey\\n'Til I find my way home to you\\nMany days I've spent\\nDrifting on through empty shores\\nWondering what's my purpose\\nWondering how to make me strong\\nI know I will falter, I know I will cry\\nI know you'll be standing by my side\\nIt's a long, long journey\\nAnd I need to be close to you\\nSometimes it seems no one understands\\nI don't even know why I do the things I do\\nWhen pride builds me up 'til I can't see my soul\\nWill you break down these walls and pull me through?\\n'Cause it's a long, long journey\\n'Til I feel that I am worth the price you paid for me on calvary\\nBeneath those stormy skies\\nWhen Satan mocks and friends turn to foes\\nIt feels like everything is out to make me lose control\\nIt's a long, long journey\\n'Til I find my way home to you\",\n",
       "       '\"When will you be home?\" she asks\\nAs we watch the planes take off\\nWe both know we have no clear answer to where my dreams may lead\\nShe\\'s watched me as I crawled and stumbled\\nAs a child, she was my world\\nAnd now to let me go, I know she bleeds\\nAnd yet she says to me\\nYou can fly so high\\nKeep your gaze upon the sky\\nI\\'ll be prayin\\' every step along the way\\nEven though it breaks my heart to know we\\'ll be so far apart\\nI love you too much to make you stay\\nBaby fly away\\nAutumn leaves fell into spring time and\\nSilver-painted hair\\nDaddy called one evening saying\\n\"We need you. Please come back\"\\nWhen I saw her laying in her bed\\nFragile as a child\\nPale just like an angel taking flight\\nI held her as I cried\\nYou can fly so high\\nKeep your gaze upon the sky\\nI\\'ll be prayin\\' every step along the way\\nEven though it breaks my heart to know we\\'ll be so far apart\\nI love you too much to make you stay\\nBaby fly away\\nOh...\\nI love you too much to make you stay\\nBaby fly away',\n",
       "       \"I woke up this morning feeling kind of blue\\nand I stumbled out of bed\\nand dragged my feet across the room\\nRight outside my front door was a rose\\nand a note that said 'Somebody Loves You'\\nBut out on the street it starts to pour\\nand before I get soaking wet,\\nA total stranger runs to give me\\nthe jacket off his back\\nI turn around to thank him\\nBut he waves me with a smile\\nI can hardly believe my eyes\\nHe puts on a halo and starts to fly\\nTake a look at the ordinary\\nDon't need to look at Paradise\\nYou could be next to\\nan angel in disguise\\nI met a good friend for lunch\\nand we had a delicious meal\\nBut I forgot to bring my wallet\\nI felt like an imbecile\\nBut she was sweet, she gave me a treat and\\nBought me a chicken sandwich\\nTo take home for tea\\nBut out on the street with nothing to eat\\nA man and his shopping cart go\\nTravelling to places,\\nCollecting social graces\\nI give him my sandwich\\nand we chatter for a while\\nI see a rainbow wash over his eyes\\nHe gives me his halo and\\nI start to fly\\nTake a look at the ordinary\\nDon't need to look for Paradise\\nYou could be next to an angel in disguise\\nDon't try to hide away from me\\nI know you're by my side\\nTake a look at the ordinary\\nDon't need to look for Paradise\\nYou could be next to\\nan angel in disguise\\nEveryday can be legendary\\nEvery minute, an endless surprise\\nYou could be the next angel in disguise\\nI woke up this morning\\nFeeling kind of new\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28051993"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = \"\"\n",
    "for ix in range(data.shape[0]):\n",
    "    cur = data[ix].split('\\n')\n",
    "    for jx in range(len(cur)):\n",
    "        #lines.append(cur[jx])\n",
    "        lines += cur[jx]\n",
    "        lines += \" \"\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh baby, how you doing? You know I'm gonna cut right to the chase Some women were made but me, mysel\n"
     ]
    }
   ],
   "source": [
    "print(lines[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    letters_only = re.sub(\"[^a-zA-Z' ]\", \"\", doc)\n",
    "    letters_only = letters_only.lower()\n",
    "    tokens = letters_only.split()\n",
    "    return tokens\n",
    "\n",
    "clean = clean_doc(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'baby', 'how', 'you', 'doing', 'you', 'know', \"i'm\", 'gonna', 'cut']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq = {}\n",
    "for ix in range(len(clean)):\n",
    "    try:\n",
    "        freq[clean[ix]] += 1\n",
    "    except:\n",
    "        freq[clean[ix]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12884\n",
      "5573084\n"
     ]
    }
   ],
   "source": [
    "new_list = []\n",
    "for wrd, f in freq.items():\n",
    "    if f > 10:\n",
    "        new_list.append(wrd)\n",
    "print(len(new_list))\n",
    "print(len(clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('your_file.txt', 'w') as f:\n",
    "    for item in lines:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "sequences = pad_sequences(sequences, maxlen = 10, padding='post')\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=10)\n",
    "\n",
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "\tresult = list()\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# truncate sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\t\tresult.append(out_word)\n",
    "\treturn ' '.join(result)\n",
    "\n",
    "# load cleaned text sequences\n",
    "#in_filename = 'republic_sequences.txt'\n",
    "#doc = load_doc(in_filename)\n",
    "#lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1\n",
    "\n",
    "# load the model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "\n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17005\n"
     ]
    }
   ],
   "source": [
    "mf = []\n",
    "words = lines.split()\n",
    "cnt = 0\n",
    "for wx in words:\n",
    "    wx = wx.lower()\n",
    "    try:\n",
    "        if freq[wx] > 10:\n",
    "            mf.append(wx)\n",
    "    except :\n",
    "        cnt += 1\n",
    "print cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oh', 'baby', 'how', 'you', 'doing', 'you', 'know', 'im', 'gonna', 'cut']\n"
     ]
    }
   ],
   "source": [
    "print mf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "vocab_size = len(mf)\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data.txt', 'w') as f:\n",
    "    for item in mf:\n",
    "        f.write(\"%s \" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
