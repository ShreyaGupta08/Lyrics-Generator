{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "filename ='lyrics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(os.pardir, data_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coldplay_songs = data[data.artist == 'coldplay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Was a long and dark December From the rooftops i remember There was snow White snow Clearly i remember From the windows they were watching While we froze down below When the future's architectured By a carnival of idiots on show You'd better lie low If you love me Won't you let me know? Was a long and dark December When the banks became cathedrals And the fog Became God Priests clutched onto bibles hollowed out to fit their rifles And the cross was held aloft Bury me in armour When i'm dead and hit the ground A love back home unfolds If you love me Won't you let me know? I don't want to be a soldier when the captain of some sinking ship would stow, far below So if you love me Why'd you let me go? I took my love down to violet hill There we sat in snow All that time she was silent still So if you love me Won't you let me know? If you love me, Won't you let me know?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldplay_songs.iloc[0].lyrics.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldplay_songs = coldplay_songs.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldplay_songs.to_csv(os.path.join(os.pardir, data_dir, 'coldplay_songs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(lyrics):\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r\"[a-z]|\\s|'\")\n",
    "    return tokenizer.tokenize(lyrics.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascii_values = [ord(' '), ord(\"'\")] + list(range(ord('a'), ord('z') + 1))\n",
    "chars = list(map(chr, ascii_values))\n",
    "indices = list(range(len(ascii_values)))\n",
    "char_to_index = dict(zip(chars, indices))\n",
    "index_to_char = dict(zip(indices, chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentences(tokenized_lyrics, max_len=20, step=1):\n",
    "    sentences = []\n",
    "    next_char = []\n",
    "    for i in range(0, len(tokenized_lyrics) - max_len, step):\n",
    "        sentences.append(tokenized_lyrics[i:i + max_len])\n",
    "        next_char.append(tokenized_lyrics[i + max_len])\n",
    "        \n",
    "    return sentences, next_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentences(sentences, next_char, max_len=20):\n",
    "    x = np.zeros((len(sentences), max_len, len(chars)), dtype=np.int32)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.int32)\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_to_index[char]] = 1\n",
    "        y[i, char_to_index[next_char[i]]] = 1\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lyrics(lyrics):\n",
    "    tokenized_lyrics = tokenize_lyrics(lyrics)\n",
    "    sentences, next_char = generate_sentences(tokenized_lyrics)\n",
    "    x, y = vectorize_sentences(sentences, next_char)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collect_lyrics(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
